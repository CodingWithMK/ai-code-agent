# ğŸ§  AI Code Agent â€” Local Dev Assistant

> A modular,  Generative AI code agent that reads, understands, and generates code using **Ollama**, **LlamaIndex**, and **LlamaParse** â€” all running locally.

---

## ğŸ“¸ Project Overview

### Streamlit Web App

![AI Code Agent UI](assets/web-app-agent.png)

### Generated Output Example

![Generated Code](assets/code-output.png)

---

## ğŸš€ About the Project

The **AI Code Agent** is a local Generative AI system capable of:

* Reading and analyzing documentation or code files
* Using tools (`code_reader`, `api_documentation`) to extract context
* Generating and structuring new code
* Operating **entirely offline** through local Ollama LLMs

It was developed for the **Global AI Hub â€“ Generative AI Bootcamp 2025**, combining both **RAG (Retrieval-Augmented Generation)** and **Agentic reasoning**.

---

## ğŸ§© Modular Architecture

The project is now fully modular and organized as follows:

```
ai-code-agent/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py         # Streamlit-based web UI
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ ai_code_agent.py     # Core agent class (LLMs, tools, RAG)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ ollama_utils.py      # Health check & warm-up
â”‚   â”‚   â”œâ”€â”€ rag.py               # Document parsing and vector indexing
â”‚   â”‚   â””â”€â”€ structuring.py       # Pydantic schema + JSON pipeline
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â””â”€â”€ code_reader.py       # FunctionTool for reading local code files
â”‚   â”œâ”€â”€ config.py                # Centralized environment configuration
â”‚   â””â”€â”€ prompts.py               # Agent context and JSON schema templates
â”œâ”€â”€ data/                        # Input documents or code
â”œâ”€â”€ output/                      # Generated scripts
â”œâ”€â”€ main.py                      # CLI runner (new modular version)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## ğŸ” Environment Configuration

1. Copy the example environment file and edit it:

   ```bash
   cp .env.example .env
   ```

2. Obtain a **LlamaCloud API key** by creating an account at
   [https://cloud.llamaindex.ai](https://cloud.llamaindex.ai)

3. Paste your key into `.env`:

   ```env
   LLAMA_CLOUD_API_KEY=your_llamacloud_api_key_here
   ```

> This key allows **LlamaParse** to process PDFs and extract structured text.
> Without it, the agent falls back to a default document reader.

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/yourusername/ai-code-agent.git
cd ai-code-agent
```

### 2ï¸âƒ£ Create a virtual environment

Using **uv** (recommended):

```bash
uv sync
```

or classic `venv`:

```bash
python -m venv venv
source venv/bin/activate     # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3ï¸âƒ£ Configure environment

Follow the previous step to fill `.env` with your Ollama models and (optional) LlamaCloud key.

### 4ï¸âƒ£ Pull Ollama models

```bash
ollama pull mistral:latest
ollama pull codellama:latest
```

### 5ï¸âƒ£ Start Ollama

```bash
ollama serve
```

---

## ğŸ–¥ï¸ Running the Agent

### ğŸ§  **Option 1: Streamlit Web App**

Launch the interactive dashboard:

```bash
uv run streamlit run app/streamlit_app.py
```

Then open [http://localhost:8501](http://localhost:8501) in your browser.

From the UI, you can:

* Upload files to `/data`
* Query the agent
* Generate structured Python files
* Download code outputs directly from `/output`

---

### ğŸ’» **Option 2: CLI Mode**

Run directly in the terminal (no Streamlit needed):

```bash
uv run python main.py
```

Choose between:

* **Plain text mode** â†’ short, descriptive answers
* **Structured mode** â†’ generates and saves code files

---

## ğŸ“Ÿ Example CLI Session

Below is a real interaction captured during testing.
It demonstrates the agent reading `test.py` and generating a new Python script that calls the POST endpoint:

```
Enter a prompt (Press q to quit): Read the contents of test.py and write a python script that calls the post endpoint to make a new item.
Mode: [p]lain text / [s]tructured file output ? [p/s]: s
Thought: The current language of the user is: English. I need to use a tool to help me answer the question.
Action: code_reader
Action Input: {'file_name': 'test.py'}
Observation: {'file_content': 'from flask import Flask, request, jsonify
...
if __name__ == "__main__":
    app.run(debug=True)
'}
Thought: I can answer without using any more tools. I'll use the user's language to answer.
Answer: To write a Python script that calls the POST endpoint to make a new item, you can follow these steps:

1. Import the necessary libraries ...
2. ...
10. Run the Flask app using the debug mode for simplicity.

Here's an example of what your script could look like:
```

from flask import Flask, request, jsonify
...
if **name** == "**main**":
app.run(debug=True)

```

âœ… Code generated  
Description: Recovered from fenced code block (fallback).

ğŸ’¾ Saved file: output/generated_code.py
```

---

## ğŸ§± Features

| Feature                   | Description                                                      |
| ------------------------- | ---------------------------------------------------------------- |
| ğŸ’¬ ReAct Agent            | Step-by-step reasoning (Thought â†’ Action â†’ Observation â†’ Answer) |
| ğŸ§  RAG with LlamaIndex    | Reads and indexes local API docs or code                         |
| ğŸ§© Modular Tools          | `code_reader`, `api_documentation`                               |
| ğŸ–¥ï¸ Streamlit UI          | Upload, query, and download code visually                        |
| âš™ï¸ CLI Mode               | Lightweight text or structured file output                       |
| ğŸ” Privacy                | 100% local execution with Ollama                                 |
| ğŸ§° LlamaParse Integration | Structured PDF parsing with LlamaCloud API key                   |

---

## ğŸ§° Example Usage Summary

| Mode                | Command                                                                       | Output                            |
| ------------------- | ----------------------------------------------------------------------------- | --------------------------------- |
| Streamlit UI        | `uv run streamlit run app/streamlit_app.py`                                   | Interactive web dashboard         |
| CLI Text Mode       | `uv run python main.py --mode plain --prompt "Explain test.py"`               | Raw reasoning text                |
| CLI Structured Mode | `uv run python main.py --mode structured --prompt "Generate client for POST"` | Saves Python file under `/output` |

---

## ğŸ§  Developer Notes

* The agentâ€™s reasoning, tool calls, and outputs are logged transparently.
* LlamaIndex orchestrates the flow; Ollama handles model inference.
* The modular `src/` layout supports easy extension â€” add new tools under `src/tools/`.

Future enhancements might include:

* ğŸ§© **Code Writer Tool** (automatic saving & diffing)
* ğŸŒ **Web Fetch Tool** (for online doc retrieval)
* ğŸª¶ **Memory Module** (persistent multi-turn reasoning)

---

## ğŸ§© Credits

Developed by **Muhammed Musab Kaya**
as part of the **Global AI Hub â€“ Generative AI Bootcamp 2025**

---

## ğŸ“œ License

This project is released under the **MIT License**.
Feel free to use, modify, and improve it â€” contributions are welcome!

---